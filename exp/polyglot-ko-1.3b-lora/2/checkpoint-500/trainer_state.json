{
  "best_metric": 2.536250114440918,
  "best_model_checkpoint": "./exp/polyglot-ko-1.3b-lora/2/checkpoint-500",
  "epoch": 4.464285714285714,
  "eval_steps": 50,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 0.21137374639511108,
      "learning_rate": 1.9910714285714287e-05,
      "loss": 3.8109,
      "step": 10
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 0.2076570987701416,
      "learning_rate": 1.9821428571428575e-05,
      "loss": 3.5297,
      "step": 20
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 0.210489422082901,
      "learning_rate": 1.973214285714286e-05,
      "loss": 3.5156,
      "step": 30
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.26109418272972107,
      "learning_rate": 1.9642857142857145e-05,
      "loss": 3.5187,
      "step": 40
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 0.23066096007823944,
      "learning_rate": 1.955357142857143e-05,
      "loss": 3.7453,
      "step": 50
    },
    {
      "epoch": 0.44642857142857145,
      "eval_loss": 3.4106249809265137,
      "eval_runtime": 0.41,
      "eval_samples_per_second": 121.965,
      "eval_steps_per_second": 31.711,
      "step": 50
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 0.25573837757110596,
      "learning_rate": 1.9464285714285715e-05,
      "loss": 3.4953,
      "step": 60
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.3625480830669403,
      "learning_rate": 1.9375e-05,
      "loss": 3.5906,
      "step": 70
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.34361162781715393,
      "learning_rate": 1.928571428571429e-05,
      "loss": 3.55,
      "step": 80
    },
    {
      "epoch": 0.8035714285714286,
      "grad_norm": 0.3135417401790619,
      "learning_rate": 1.9196428571428573e-05,
      "loss": 3.2156,
      "step": 90
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.41260942816734314,
      "learning_rate": 1.910714285714286e-05,
      "loss": 3.3922,
      "step": 100
    },
    {
      "epoch": 0.8928571428571429,
      "eval_loss": 3.2793750762939453,
      "eval_runtime": 0.4117,
      "eval_samples_per_second": 121.449,
      "eval_steps_per_second": 31.577,
      "step": 100
    },
    {
      "epoch": 0.9821428571428571,
      "grad_norm": 0.4031710624694824,
      "learning_rate": 1.9017857142857143e-05,
      "loss": 3.4875,
      "step": 110
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.3956420421600342,
      "learning_rate": 1.892857142857143e-05,
      "loss": 3.3312,
      "step": 120
    },
    {
      "epoch": 1.1607142857142858,
      "grad_norm": 0.4825843572616577,
      "learning_rate": 1.8839285714285717e-05,
      "loss": 3.4062,
      "step": 130
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.5195916891098022,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 3.3516,
      "step": 140
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 0.4990973472595215,
      "learning_rate": 1.8660714285714287e-05,
      "loss": 3.4156,
      "step": 150
    },
    {
      "epoch": 1.3392857142857144,
      "eval_loss": 3.106250047683716,
      "eval_runtime": 0.4046,
      "eval_samples_per_second": 123.587,
      "eval_steps_per_second": 32.133,
      "step": 150
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.5986710786819458,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 3.0672,
      "step": 160
    },
    {
      "epoch": 1.5178571428571428,
      "grad_norm": 0.4586062431335449,
      "learning_rate": 1.848214285714286e-05,
      "loss": 3.0594,
      "step": 170
    },
    {
      "epoch": 1.6071428571428572,
      "grad_norm": 0.5412827134132385,
      "learning_rate": 1.8392857142857142e-05,
      "loss": 3.2672,
      "step": 180
    },
    {
      "epoch": 1.6964285714285714,
      "grad_norm": 0.4638323187828064,
      "learning_rate": 1.830357142857143e-05,
      "loss": 3.0125,
      "step": 190
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.6294122338294983,
      "learning_rate": 1.8214285714285715e-05,
      "loss": 3.0312,
      "step": 200
    },
    {
      "epoch": 1.7857142857142856,
      "eval_loss": 2.9375,
      "eval_runtime": 0.4135,
      "eval_samples_per_second": 120.926,
      "eval_steps_per_second": 31.441,
      "step": 200
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.7494852542877197,
      "learning_rate": 1.8125e-05,
      "loss": 2.9203,
      "step": 210
    },
    {
      "epoch": 1.9642857142857144,
      "grad_norm": 0.5168684720993042,
      "learning_rate": 1.803571428571429e-05,
      "loss": 3.0047,
      "step": 220
    },
    {
      "epoch": 2.0535714285714284,
      "grad_norm": 0.593038022518158,
      "learning_rate": 1.7946428571428573e-05,
      "loss": 2.8969,
      "step": 230
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.6180576682090759,
      "learning_rate": 1.785714285714286e-05,
      "loss": 2.9328,
      "step": 240
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 0.524493932723999,
      "learning_rate": 1.7767857142857143e-05,
      "loss": 3.075,
      "step": 250
    },
    {
      "epoch": 2.232142857142857,
      "eval_loss": 2.8006250858306885,
      "eval_runtime": 0.3954,
      "eval_samples_per_second": 126.454,
      "eval_steps_per_second": 32.878,
      "step": 250
    },
    {
      "epoch": 2.3214285714285716,
      "grad_norm": 0.5899754762649536,
      "learning_rate": 1.767857142857143e-05,
      "loss": 2.8578,
      "step": 260
    },
    {
      "epoch": 2.4107142857142856,
      "grad_norm": 0.46867772936820984,
      "learning_rate": 1.7589285714285717e-05,
      "loss": 2.7469,
      "step": 270
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6418992877006531,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 2.8375,
      "step": 280
    },
    {
      "epoch": 2.5892857142857144,
      "grad_norm": 0.6271042823791504,
      "learning_rate": 1.7410714285714287e-05,
      "loss": 2.8906,
      "step": 290
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.5493728518486023,
      "learning_rate": 1.7321428571428572e-05,
      "loss": 2.9672,
      "step": 300
    },
    {
      "epoch": 2.678571428571429,
      "eval_loss": 2.718125104904175,
      "eval_runtime": 0.4122,
      "eval_samples_per_second": 121.292,
      "eval_steps_per_second": 31.536,
      "step": 300
    },
    {
      "epoch": 2.767857142857143,
      "grad_norm": 0.48904117941856384,
      "learning_rate": 1.723214285714286e-05,
      "loss": 2.8828,
      "step": 310
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.6657999753952026,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 2.8219,
      "step": 320
    },
    {
      "epoch": 2.946428571428571,
      "grad_norm": 0.5290120244026184,
      "learning_rate": 1.705357142857143e-05,
      "loss": 2.7516,
      "step": 330
    },
    {
      "epoch": 3.0357142857142856,
      "grad_norm": 0.576696515083313,
      "learning_rate": 1.6964285714285715e-05,
      "loss": 2.6766,
      "step": 340
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.5065906047821045,
      "learning_rate": 1.6875e-05,
      "loss": 2.8906,
      "step": 350
    },
    {
      "epoch": 3.125,
      "eval_loss": 2.656874895095825,
      "eval_runtime": 0.3974,
      "eval_samples_per_second": 125.832,
      "eval_steps_per_second": 32.716,
      "step": 350
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 0.6068034768104553,
      "learning_rate": 1.678571428571429e-05,
      "loss": 2.7047,
      "step": 360
    },
    {
      "epoch": 3.3035714285714284,
      "grad_norm": 0.6969396471977234,
      "learning_rate": 1.6696428571428574e-05,
      "loss": 2.6609,
      "step": 370
    },
    {
      "epoch": 3.392857142857143,
      "grad_norm": 0.5688621997833252,
      "learning_rate": 1.660714285714286e-05,
      "loss": 2.7953,
      "step": 380
    },
    {
      "epoch": 3.482142857142857,
      "grad_norm": 0.7880678772926331,
      "learning_rate": 1.6517857142857144e-05,
      "loss": 2.7781,
      "step": 390
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.6696380376815796,
      "learning_rate": 1.642857142857143e-05,
      "loss": 2.7344,
      "step": 400
    },
    {
      "epoch": 3.571428571428571,
      "eval_loss": 2.6081249713897705,
      "eval_runtime": 0.4109,
      "eval_samples_per_second": 121.693,
      "eval_steps_per_second": 31.64,
      "step": 400
    },
    {
      "epoch": 3.6607142857142856,
      "grad_norm": 0.6302980780601501,
      "learning_rate": 1.6339285714285717e-05,
      "loss": 2.6313,
      "step": 410
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.5667483806610107,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 2.7016,
      "step": 420
    },
    {
      "epoch": 3.8392857142857144,
      "grad_norm": 0.5890777111053467,
      "learning_rate": 1.6160714285714287e-05,
      "loss": 2.6547,
      "step": 430
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 0.6391167044639587,
      "learning_rate": 1.6071428571428572e-05,
      "loss": 2.5063,
      "step": 440
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 0.7406922578811646,
      "learning_rate": 1.598214285714286e-05,
      "loss": 2.5844,
      "step": 450
    },
    {
      "epoch": 4.017857142857143,
      "eval_loss": 2.5687499046325684,
      "eval_runtime": 0.4111,
      "eval_samples_per_second": 121.632,
      "eval_steps_per_second": 31.624,
      "step": 450
    },
    {
      "epoch": 4.107142857142857,
      "grad_norm": 0.5377808213233948,
      "learning_rate": 1.5892857142857142e-05,
      "loss": 2.6313,
      "step": 460
    },
    {
      "epoch": 4.196428571428571,
      "grad_norm": 0.6051700711250305,
      "learning_rate": 1.580357142857143e-05,
      "loss": 2.8125,
      "step": 470
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.5757372975349426,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 2.4406,
      "step": 480
    },
    {
      "epoch": 4.375,
      "grad_norm": 0.6849559545516968,
      "learning_rate": 1.5625e-05,
      "loss": 2.6859,
      "step": 490
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.6242142915725708,
      "learning_rate": 1.553571428571429e-05,
      "loss": 2.6156,
      "step": 500
    },
    {
      "epoch": 4.464285714285714,
      "eval_loss": 2.536250114440918,
      "eval_runtime": 0.4211,
      "eval_samples_per_second": 118.723,
      "eval_steps_per_second": 30.868,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 2240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 747578453852160.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
