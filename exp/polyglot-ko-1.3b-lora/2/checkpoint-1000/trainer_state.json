{
  "best_metric": 2.361875057220459,
  "best_model_checkpoint": "./exp/polyglot-ko-1.3b-lora/2/checkpoint-1000",
  "epoch": 8.928571428571429,
  "eval_steps": 50,
  "global_step": 1000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08928571428571429,
      "grad_norm": 0.21137374639511108,
      "learning_rate": 1.9910714285714287e-05,
      "loss": 3.8109,
      "step": 10
    },
    {
      "epoch": 0.17857142857142858,
      "grad_norm": 0.2076570987701416,
      "learning_rate": 1.9821428571428575e-05,
      "loss": 3.5297,
      "step": 20
    },
    {
      "epoch": 0.26785714285714285,
      "grad_norm": 0.210489422082901,
      "learning_rate": 1.973214285714286e-05,
      "loss": 3.5156,
      "step": 30
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.26109418272972107,
      "learning_rate": 1.9642857142857145e-05,
      "loss": 3.5187,
      "step": 40
    },
    {
      "epoch": 0.44642857142857145,
      "grad_norm": 0.23066096007823944,
      "learning_rate": 1.955357142857143e-05,
      "loss": 3.7453,
      "step": 50
    },
    {
      "epoch": 0.44642857142857145,
      "eval_loss": 3.4106249809265137,
      "eval_runtime": 0.41,
      "eval_samples_per_second": 121.965,
      "eval_steps_per_second": 31.711,
      "step": 50
    },
    {
      "epoch": 0.5357142857142857,
      "grad_norm": 0.25573837757110596,
      "learning_rate": 1.9464285714285715e-05,
      "loss": 3.4953,
      "step": 60
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.3625480830669403,
      "learning_rate": 1.9375e-05,
      "loss": 3.5906,
      "step": 70
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.34361162781715393,
      "learning_rate": 1.928571428571429e-05,
      "loss": 3.55,
      "step": 80
    },
    {
      "epoch": 0.8035714285714286,
      "grad_norm": 0.3135417401790619,
      "learning_rate": 1.9196428571428573e-05,
      "loss": 3.2156,
      "step": 90
    },
    {
      "epoch": 0.8928571428571429,
      "grad_norm": 0.41260942816734314,
      "learning_rate": 1.910714285714286e-05,
      "loss": 3.3922,
      "step": 100
    },
    {
      "epoch": 0.8928571428571429,
      "eval_loss": 3.2793750762939453,
      "eval_runtime": 0.4117,
      "eval_samples_per_second": 121.449,
      "eval_steps_per_second": 31.577,
      "step": 100
    },
    {
      "epoch": 0.9821428571428571,
      "grad_norm": 0.4031710624694824,
      "learning_rate": 1.9017857142857143e-05,
      "loss": 3.4875,
      "step": 110
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.3956420421600342,
      "learning_rate": 1.892857142857143e-05,
      "loss": 3.3312,
      "step": 120
    },
    {
      "epoch": 1.1607142857142858,
      "grad_norm": 0.4825843572616577,
      "learning_rate": 1.8839285714285717e-05,
      "loss": 3.4062,
      "step": 130
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.5195916891098022,
      "learning_rate": 1.8750000000000002e-05,
      "loss": 3.3516,
      "step": 140
    },
    {
      "epoch": 1.3392857142857144,
      "grad_norm": 0.4990973472595215,
      "learning_rate": 1.8660714285714287e-05,
      "loss": 3.4156,
      "step": 150
    },
    {
      "epoch": 1.3392857142857144,
      "eval_loss": 3.106250047683716,
      "eval_runtime": 0.4046,
      "eval_samples_per_second": 123.587,
      "eval_steps_per_second": 32.133,
      "step": 150
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.5986710786819458,
      "learning_rate": 1.8571428571428575e-05,
      "loss": 3.0672,
      "step": 160
    },
    {
      "epoch": 1.5178571428571428,
      "grad_norm": 0.4586062431335449,
      "learning_rate": 1.848214285714286e-05,
      "loss": 3.0594,
      "step": 170
    },
    {
      "epoch": 1.6071428571428572,
      "grad_norm": 0.5412827134132385,
      "learning_rate": 1.8392857142857142e-05,
      "loss": 3.2672,
      "step": 180
    },
    {
      "epoch": 1.6964285714285714,
      "grad_norm": 0.4638323187828064,
      "learning_rate": 1.830357142857143e-05,
      "loss": 3.0125,
      "step": 190
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.6294122338294983,
      "learning_rate": 1.8214285714285715e-05,
      "loss": 3.0312,
      "step": 200
    },
    {
      "epoch": 1.7857142857142856,
      "eval_loss": 2.9375,
      "eval_runtime": 0.4135,
      "eval_samples_per_second": 120.926,
      "eval_steps_per_second": 31.441,
      "step": 200
    },
    {
      "epoch": 1.875,
      "grad_norm": 0.7494852542877197,
      "learning_rate": 1.8125e-05,
      "loss": 2.9203,
      "step": 210
    },
    {
      "epoch": 1.9642857142857144,
      "grad_norm": 0.5168684720993042,
      "learning_rate": 1.803571428571429e-05,
      "loss": 3.0047,
      "step": 220
    },
    {
      "epoch": 2.0535714285714284,
      "grad_norm": 0.593038022518158,
      "learning_rate": 1.7946428571428573e-05,
      "loss": 2.8969,
      "step": 230
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.6180576682090759,
      "learning_rate": 1.785714285714286e-05,
      "loss": 2.9328,
      "step": 240
    },
    {
      "epoch": 2.232142857142857,
      "grad_norm": 0.524493932723999,
      "learning_rate": 1.7767857142857143e-05,
      "loss": 3.075,
      "step": 250
    },
    {
      "epoch": 2.232142857142857,
      "eval_loss": 2.8006250858306885,
      "eval_runtime": 0.3954,
      "eval_samples_per_second": 126.454,
      "eval_steps_per_second": 32.878,
      "step": 250
    },
    {
      "epoch": 2.3214285714285716,
      "grad_norm": 0.5899754762649536,
      "learning_rate": 1.767857142857143e-05,
      "loss": 2.8578,
      "step": 260
    },
    {
      "epoch": 2.4107142857142856,
      "grad_norm": 0.46867772936820984,
      "learning_rate": 1.7589285714285717e-05,
      "loss": 2.7469,
      "step": 270
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.6418992877006531,
      "learning_rate": 1.7500000000000002e-05,
      "loss": 2.8375,
      "step": 280
    },
    {
      "epoch": 2.5892857142857144,
      "grad_norm": 0.6271042823791504,
      "learning_rate": 1.7410714285714287e-05,
      "loss": 2.8906,
      "step": 290
    },
    {
      "epoch": 2.678571428571429,
      "grad_norm": 0.5493728518486023,
      "learning_rate": 1.7321428571428572e-05,
      "loss": 2.9672,
      "step": 300
    },
    {
      "epoch": 2.678571428571429,
      "eval_loss": 2.718125104904175,
      "eval_runtime": 0.4122,
      "eval_samples_per_second": 121.292,
      "eval_steps_per_second": 31.536,
      "step": 300
    },
    {
      "epoch": 2.767857142857143,
      "grad_norm": 0.48904117941856384,
      "learning_rate": 1.723214285714286e-05,
      "loss": 2.8828,
      "step": 310
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.6657999753952026,
      "learning_rate": 1.7142857142857142e-05,
      "loss": 2.8219,
      "step": 320
    },
    {
      "epoch": 2.946428571428571,
      "grad_norm": 0.5290120244026184,
      "learning_rate": 1.705357142857143e-05,
      "loss": 2.7516,
      "step": 330
    },
    {
      "epoch": 3.0357142857142856,
      "grad_norm": 0.576696515083313,
      "learning_rate": 1.6964285714285715e-05,
      "loss": 2.6766,
      "step": 340
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.5065906047821045,
      "learning_rate": 1.6875e-05,
      "loss": 2.8906,
      "step": 350
    },
    {
      "epoch": 3.125,
      "eval_loss": 2.656874895095825,
      "eval_runtime": 0.3974,
      "eval_samples_per_second": 125.832,
      "eval_steps_per_second": 32.716,
      "step": 350
    },
    {
      "epoch": 3.2142857142857144,
      "grad_norm": 0.6068034768104553,
      "learning_rate": 1.678571428571429e-05,
      "loss": 2.7047,
      "step": 360
    },
    {
      "epoch": 3.3035714285714284,
      "grad_norm": 0.6969396471977234,
      "learning_rate": 1.6696428571428574e-05,
      "loss": 2.6609,
      "step": 370
    },
    {
      "epoch": 3.392857142857143,
      "grad_norm": 0.5688621997833252,
      "learning_rate": 1.660714285714286e-05,
      "loss": 2.7953,
      "step": 380
    },
    {
      "epoch": 3.482142857142857,
      "grad_norm": 0.7880678772926331,
      "learning_rate": 1.6517857142857144e-05,
      "loss": 2.7781,
      "step": 390
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.6696380376815796,
      "learning_rate": 1.642857142857143e-05,
      "loss": 2.7344,
      "step": 400
    },
    {
      "epoch": 3.571428571428571,
      "eval_loss": 2.6081249713897705,
      "eval_runtime": 0.4109,
      "eval_samples_per_second": 121.693,
      "eval_steps_per_second": 31.64,
      "step": 400
    },
    {
      "epoch": 3.6607142857142856,
      "grad_norm": 0.6302980780601501,
      "learning_rate": 1.6339285714285717e-05,
      "loss": 2.6313,
      "step": 410
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.5667483806610107,
      "learning_rate": 1.6250000000000002e-05,
      "loss": 2.7016,
      "step": 420
    },
    {
      "epoch": 3.8392857142857144,
      "grad_norm": 0.5890777111053467,
      "learning_rate": 1.6160714285714287e-05,
      "loss": 2.6547,
      "step": 430
    },
    {
      "epoch": 3.928571428571429,
      "grad_norm": 0.6391167044639587,
      "learning_rate": 1.6071428571428572e-05,
      "loss": 2.5063,
      "step": 440
    },
    {
      "epoch": 4.017857142857143,
      "grad_norm": 0.7406922578811646,
      "learning_rate": 1.598214285714286e-05,
      "loss": 2.5844,
      "step": 450
    },
    {
      "epoch": 4.017857142857143,
      "eval_loss": 2.5687499046325684,
      "eval_runtime": 0.4111,
      "eval_samples_per_second": 121.632,
      "eval_steps_per_second": 31.624,
      "step": 450
    },
    {
      "epoch": 4.107142857142857,
      "grad_norm": 0.5377808213233948,
      "learning_rate": 1.5892857142857142e-05,
      "loss": 2.6313,
      "step": 460
    },
    {
      "epoch": 4.196428571428571,
      "grad_norm": 0.6051700711250305,
      "learning_rate": 1.580357142857143e-05,
      "loss": 2.8125,
      "step": 470
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.5757372975349426,
      "learning_rate": 1.5714285714285715e-05,
      "loss": 2.4406,
      "step": 480
    },
    {
      "epoch": 4.375,
      "grad_norm": 0.6849559545516968,
      "learning_rate": 1.5625e-05,
      "loss": 2.6859,
      "step": 490
    },
    {
      "epoch": 4.464285714285714,
      "grad_norm": 0.6242142915725708,
      "learning_rate": 1.553571428571429e-05,
      "loss": 2.6156,
      "step": 500
    },
    {
      "epoch": 4.464285714285714,
      "eval_loss": 2.536250114440918,
      "eval_runtime": 0.4211,
      "eval_samples_per_second": 118.723,
      "eval_steps_per_second": 30.868,
      "step": 500
    },
    {
      "epoch": 4.553571428571429,
      "grad_norm": 0.5909423232078552,
      "learning_rate": 1.5446428571428574e-05,
      "loss": 2.6812,
      "step": 510
    },
    {
      "epoch": 4.642857142857143,
      "grad_norm": 0.717409610748291,
      "learning_rate": 1.535714285714286e-05,
      "loss": 2.6391,
      "step": 520
    },
    {
      "epoch": 4.732142857142857,
      "grad_norm": 0.5612279176712036,
      "learning_rate": 1.5267857142857144e-05,
      "loss": 2.6109,
      "step": 530
    },
    {
      "epoch": 4.821428571428571,
      "grad_norm": 0.8164576888084412,
      "learning_rate": 1.5178571428571429e-05,
      "loss": 2.5797,
      "step": 540
    },
    {
      "epoch": 4.910714285714286,
      "grad_norm": 0.7153419852256775,
      "learning_rate": 1.5089285714285715e-05,
      "loss": 2.5375,
      "step": 550
    },
    {
      "epoch": 4.910714285714286,
      "eval_loss": 2.5093750953674316,
      "eval_runtime": 0.428,
      "eval_samples_per_second": 116.826,
      "eval_steps_per_second": 30.375,
      "step": 550
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.9239504933357239,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 2.5289,
      "step": 560
    },
    {
      "epoch": 5.089285714285714,
      "grad_norm": 0.7677070498466492,
      "learning_rate": 1.4910714285714287e-05,
      "loss": 2.3359,
      "step": 570
    },
    {
      "epoch": 5.178571428571429,
      "grad_norm": 0.708517849445343,
      "learning_rate": 1.4821428571428574e-05,
      "loss": 2.6906,
      "step": 580
    },
    {
      "epoch": 5.267857142857143,
      "grad_norm": 0.7137799263000488,
      "learning_rate": 1.4732142857142859e-05,
      "loss": 2.5234,
      "step": 590
    },
    {
      "epoch": 5.357142857142857,
      "grad_norm": 0.6510134935379028,
      "learning_rate": 1.4642857142857144e-05,
      "loss": 2.4172,
      "step": 600
    },
    {
      "epoch": 5.357142857142857,
      "eval_loss": 2.4831249713897705,
      "eval_runtime": 0.4094,
      "eval_samples_per_second": 122.142,
      "eval_steps_per_second": 31.757,
      "step": 600
    },
    {
      "epoch": 5.446428571428571,
      "grad_norm": 0.5994876027107239,
      "learning_rate": 1.4553571428571429e-05,
      "loss": 2.5312,
      "step": 610
    },
    {
      "epoch": 5.535714285714286,
      "grad_norm": 0.7311949133872986,
      "learning_rate": 1.4464285714285715e-05,
      "loss": 2.4945,
      "step": 620
    },
    {
      "epoch": 5.625,
      "grad_norm": 0.6167783737182617,
      "learning_rate": 1.4375e-05,
      "loss": 2.6594,
      "step": 630
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.7568943500518799,
      "learning_rate": 1.4285714285714287e-05,
      "loss": 2.5156,
      "step": 640
    },
    {
      "epoch": 5.803571428571429,
      "grad_norm": 0.8817871809005737,
      "learning_rate": 1.4196428571428574e-05,
      "loss": 2.4836,
      "step": 650
    },
    {
      "epoch": 5.803571428571429,
      "eval_loss": 2.4618749618530273,
      "eval_runtime": 0.4034,
      "eval_samples_per_second": 123.957,
      "eval_steps_per_second": 32.229,
      "step": 650
    },
    {
      "epoch": 5.892857142857143,
      "grad_norm": 0.8050828576087952,
      "learning_rate": 1.4107142857142859e-05,
      "loss": 2.6172,
      "step": 660
    },
    {
      "epoch": 5.982142857142857,
      "grad_norm": 0.6767444014549255,
      "learning_rate": 1.4017857142857144e-05,
      "loss": 2.4844,
      "step": 670
    },
    {
      "epoch": 6.071428571428571,
      "grad_norm": 0.8569750189781189,
      "learning_rate": 1.3928571428571429e-05,
      "loss": 2.5609,
      "step": 680
    },
    {
      "epoch": 6.160714285714286,
      "grad_norm": 0.9145105481147766,
      "learning_rate": 1.3839285714285715e-05,
      "loss": 2.4547,
      "step": 690
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.8488553762435913,
      "learning_rate": 1.375e-05,
      "loss": 2.4734,
      "step": 700
    },
    {
      "epoch": 6.25,
      "eval_loss": 2.444999933242798,
      "eval_runtime": 0.4005,
      "eval_samples_per_second": 124.854,
      "eval_steps_per_second": 32.462,
      "step": 700
    },
    {
      "epoch": 6.339285714285714,
      "grad_norm": 0.692187488079071,
      "learning_rate": 1.3660714285714287e-05,
      "loss": 2.3961,
      "step": 710
    },
    {
      "epoch": 6.428571428571429,
      "grad_norm": 0.8646299839019775,
      "learning_rate": 1.3571428571428574e-05,
      "loss": 2.5734,
      "step": 720
    },
    {
      "epoch": 6.517857142857143,
      "grad_norm": 0.800898015499115,
      "learning_rate": 1.3482142857142859e-05,
      "loss": 2.3602,
      "step": 730
    },
    {
      "epoch": 6.607142857142857,
      "grad_norm": 0.8756415843963623,
      "learning_rate": 1.3392857142857142e-05,
      "loss": 2.4969,
      "step": 740
    },
    {
      "epoch": 6.696428571428571,
      "grad_norm": 0.6331586837768555,
      "learning_rate": 1.3303571428571429e-05,
      "loss": 2.4594,
      "step": 750
    },
    {
      "epoch": 6.696428571428571,
      "eval_loss": 2.4262499809265137,
      "eval_runtime": 0.4114,
      "eval_samples_per_second": 121.54,
      "eval_steps_per_second": 31.6,
      "step": 750
    },
    {
      "epoch": 6.785714285714286,
      "grad_norm": 0.749420166015625,
      "learning_rate": 1.3214285714285716e-05,
      "loss": 2.4609,
      "step": 760
    },
    {
      "epoch": 6.875,
      "grad_norm": 0.9024516344070435,
      "learning_rate": 1.3125e-05,
      "loss": 2.5578,
      "step": 770
    },
    {
      "epoch": 6.964285714285714,
      "grad_norm": 0.6487221121788025,
      "learning_rate": 1.3035714285714287e-05,
      "loss": 2.4703,
      "step": 780
    },
    {
      "epoch": 7.053571428571429,
      "grad_norm": 0.6945983171463013,
      "learning_rate": 1.2946428571428574e-05,
      "loss": 2.5187,
      "step": 790
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.7291197776794434,
      "learning_rate": 1.2857142857142859e-05,
      "loss": 2.4719,
      "step": 800
    },
    {
      "epoch": 7.142857142857143,
      "eval_loss": 2.4149999618530273,
      "eval_runtime": 0.4316,
      "eval_samples_per_second": 115.838,
      "eval_steps_per_second": 30.118,
      "step": 800
    },
    {
      "epoch": 7.232142857142857,
      "grad_norm": 0.7554000616073608,
      "learning_rate": 1.2767857142857142e-05,
      "loss": 2.4375,
      "step": 810
    },
    {
      "epoch": 7.321428571428571,
      "grad_norm": 0.8524067997932434,
      "learning_rate": 1.2678571428571429e-05,
      "loss": 2.4234,
      "step": 820
    },
    {
      "epoch": 7.410714285714286,
      "grad_norm": 0.8413822650909424,
      "learning_rate": 1.2589285714285716e-05,
      "loss": 2.4516,
      "step": 830
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.8895707130432129,
      "learning_rate": 1.25e-05,
      "loss": 2.3625,
      "step": 840
    },
    {
      "epoch": 7.589285714285714,
      "grad_norm": 0.6774404644966125,
      "learning_rate": 1.2410714285714287e-05,
      "loss": 2.3805,
      "step": 850
    },
    {
      "epoch": 7.589285714285714,
      "eval_loss": 2.3993749618530273,
      "eval_runtime": 0.407,
      "eval_samples_per_second": 122.861,
      "eval_steps_per_second": 31.944,
      "step": 850
    },
    {
      "epoch": 7.678571428571429,
      "grad_norm": 0.775874674320221,
      "learning_rate": 1.2321428571428572e-05,
      "loss": 2.5125,
      "step": 860
    },
    {
      "epoch": 7.767857142857143,
      "grad_norm": 0.8110480904579163,
      "learning_rate": 1.2232142857142859e-05,
      "loss": 2.3797,
      "step": 870
    },
    {
      "epoch": 7.857142857142857,
      "grad_norm": 0.9679687023162842,
      "learning_rate": 1.2142857142857142e-05,
      "loss": 2.3398,
      "step": 880
    },
    {
      "epoch": 7.946428571428571,
      "grad_norm": 0.7394080758094788,
      "learning_rate": 1.2053571428571429e-05,
      "loss": 2.2883,
      "step": 890
    },
    {
      "epoch": 8.035714285714286,
      "grad_norm": 0.8283305168151855,
      "learning_rate": 1.1964285714285716e-05,
      "loss": 2.3766,
      "step": 900
    },
    {
      "epoch": 8.035714285714286,
      "eval_loss": 2.387500047683716,
      "eval_runtime": 0.402,
      "eval_samples_per_second": 124.39,
      "eval_steps_per_second": 32.341,
      "step": 900
    },
    {
      "epoch": 8.125,
      "grad_norm": 0.6303724050521851,
      "learning_rate": 1.1875e-05,
      "loss": 2.3773,
      "step": 910
    },
    {
      "epoch": 8.214285714285714,
      "grad_norm": 0.7350888252258301,
      "learning_rate": 1.1785714285714287e-05,
      "loss": 2.2687,
      "step": 920
    },
    {
      "epoch": 8.303571428571429,
      "grad_norm": 0.7498610019683838,
      "learning_rate": 1.1696428571428572e-05,
      "loss": 2.5891,
      "step": 930
    },
    {
      "epoch": 8.392857142857142,
      "grad_norm": 0.8199295997619629,
      "learning_rate": 1.1607142857142859e-05,
      "loss": 2.2398,
      "step": 940
    },
    {
      "epoch": 8.482142857142858,
      "grad_norm": 1.0255565643310547,
      "learning_rate": 1.1517857142857142e-05,
      "loss": 2.4781,
      "step": 950
    },
    {
      "epoch": 8.482142857142858,
      "eval_loss": 2.3762500286102295,
      "eval_runtime": 0.4089,
      "eval_samples_per_second": 122.266,
      "eval_steps_per_second": 31.789,
      "step": 950
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 0.8906276226043701,
      "learning_rate": 1.1428571428571429e-05,
      "loss": 2.2891,
      "step": 960
    },
    {
      "epoch": 8.660714285714286,
      "grad_norm": 0.9805454611778259,
      "learning_rate": 1.1339285714285716e-05,
      "loss": 2.4312,
      "step": 970
    },
    {
      "epoch": 8.75,
      "grad_norm": 0.8191073536872864,
      "learning_rate": 1.125e-05,
      "loss": 2.3203,
      "step": 980
    },
    {
      "epoch": 8.839285714285714,
      "grad_norm": 0.8133009076118469,
      "learning_rate": 1.1160714285714287e-05,
      "loss": 2.425,
      "step": 990
    },
    {
      "epoch": 8.928571428571429,
      "grad_norm": 0.7756767868995667,
      "learning_rate": 1.1071428571428572e-05,
      "loss": 2.4562,
      "step": 1000
    },
    {
      "epoch": 8.928571428571429,
      "eval_loss": 2.361875057220459,
      "eval_runtime": 0.4096,
      "eval_samples_per_second": 122.067,
      "eval_steps_per_second": 31.737,
      "step": 1000
    }
  ],
  "logging_steps": 10,
  "max_steps": 2240,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1495156907704320.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
