{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# file_path : each PDF File path\n",
    "file_path = '/home/csh/workspace/DACON/finance_llm/data/train_source/「FIS 이슈 & 포커스」 22-3호 《재정융자사업》.pdf'\n",
    "\n",
    "doc = fitz.open(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitz 라이브러리 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document('/home/csh/workspace/DACON/finance_llm/data/train_source/「FIS 이슈 & 포커스」 22-3호 《재정융자사업》.pdf')\n",
      "<class 'pymupdf.Document'>\n",
      "page_count :  9\n",
      "--------------------------------------------------\n",
      "get page : \n",
      "ISSUE & FOCUS\n",
      "FIS \n",
      "22-3호\n",
      "2022.11\n",
      ".\n",
      "  발행인 박용주      발행처 04637 서울특별시  중구 퇴계로 10(남대문로5가 537) 메트로타워      T 02)6908-8200      F 02)6312-8959\n",
      "작성 박정수 부연구위원, 우수연 연구원    기획\n",
      "·\n",
      "조정 심혜인 결산정보분석부장\n",
      "재정융자사업\n",
      "1  들어가며\n",
      "2  재정융자사업의 개념과 의의\n",
      "3  2023년도 예산안 재정융자사업 현황\n",
      "4  재정융자사업의 주요 현안\n",
      "5  나가며\n",
      "\n",
      "--------------------------------------------------\n",
      "dtype of get_text(): <class 'str'>\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(doc)\n",
    "print(type(doc))\n",
    "print(\"page_count : \",end=\" \")\n",
    "print(doc.page_count)\n",
    "print(\"-\"*50)\n",
    "print(\"get page : \")\n",
    "print(doc[0].get_text())\n",
    "print(\"-\"*50)\n",
    "print(\"dtype of get_text(): \",end=\"\")\n",
    "print(type(doc[0].get_text()))\n",
    "print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitter\n",
    "PDF에서 얻은 문자열 데이터를 청크 단위로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "\n",
    "text = doc[0].get_text()\n",
    "\n",
    "# 모든 페이지의 텍스트 추출\n",
    "for page in doc:\n",
    "    text += page.get_text()\n",
    "    \n",
    "# 텍스트를 chunk로 분할\n",
    "chunk_size=800\n",
    "chunk_overlap=50\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "\n",
    "chunk_temp = splitter.split_text(text)\n",
    "# Document 객체 리스트 생성\n",
    "chunks = [Document(page_content=t) for t in chunk_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISSUE & FOCUS\\nFIS \\n22-3호\\n2022.11\\n.\\n  발행인 박용주      발행처 04637 서울특별시  중구 퇴계로 10(남대문로5가 537) 메트로타워      T 02)6908-8200      F 02)6312-8959\\n작성 박정수 부연구위원, 우수연 연구원    기획\\n·\\n조정 심혜인 결산정보분석부장\\n재정융자사업\\n1  들어가며\\n2  재정융자사업의 개념과 의의\\n3  2023년도 예산안 재정융자사업 현황\\n4  재정융자사업의 주요 현안\\n5  나가며\\nISSUE & FOCUS\\nFIS \\n22-3호\\n2022.11\\n.\\n  발행인 박용주      발행처 04637 서울특별시  중구 퇴계로 10(남대문로5가 537) 메트로타워      T 02)6908-8200      F 02)6312-8959\\n작성 박정수 부연구위원, 우수연 연구원    기획\\n·\\n조정 심혜인 결산정보분석부장\\n재정융자사업\\n1  들어가며\\n2  재정융자사업의 개념과 의의\\n3  2023년도 예산안 재정융자사업 현황\\n4  재정융자사업의 주요 현안\\n5  나가며\\n02\\n03\\nFIS    ISSUE & FOCUS \\n                   들어가며\\nISSUE   왜 재정융자사업에 주목하는가?\\n\\x03\\n재정융자사업은 정부가 자금을 민간의 사적 경제주체에 대해 대출해 주고 회수하는 활동을 말하며, 정부\\n의 다양한 금융활동 중 직접대출과 전대 방식에 해당(재무부, 1993; 한국재정정보원, 2019)\\n    - \\x03\\n정부의 금융활동은 직접융자·전대 외에도 금리 차액에 대한 보상(이차보전), 기업의 신용심사 및 보증(신용보'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector DB\n",
    "만든 Document 데이터들을 Vector DB에 저장\n",
    "\n",
    "- **FAISS : 파시스 (Facebook AI Similarity Search)**\n",
    "\n",
    "대량의 고차원 벡터에서 유사성 검색 및 클러스터링을 빠르고 효율적으로 수행<br>\n",
    "\n",
    "\n",
    "`from_documents` 클래스 메서드는 문서 리스트와 임베딩 함수를 사용하여 FAISS 벡터 저장소를 생성<br>\n",
    "<파라미터>로 임베딩 함수(Embeddings)과 데이터(List[Document]) 입력 <br>\n",
    "<반환값> `VectorStore`: 문서와 임베딩으로 초기화된 벡터 저장소 인스턴스\n",
    "\n",
    "- **VectorStore란**\n",
    "자연어 처리(NLP) \n",
    "\n",
    "및 기계 학습 분야에서 벡터 검색을 위한 효율적인 데이터 저장 및 검색 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "def create_vector_db(chunks, model_path=\"intfloat/multilingual-e5-small\"):\n",
    "    \"\"\"FAISS DB 생성\"\"\"\n",
    "    # 임베딩 모델 설정\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    # FAISS DB 생성 및 반환\n",
    "    db = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "    return db\n",
    "\n",
    "\n",
    "db = create_vector_db(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x7f27389ab220>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.save_local(\"./save_fasiss\") # 이렇게 저장하고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<langchain_community.docstore.in_memory.InMemoryDocstore object at 0x7f280a9f7cd0>, {0: 'ee550deb-713a-4c0a-a52c-0d20facf956f', 1: '24e7305e-b957-4210-9b96-514cd651cc21', 2: 'e4c88563-6eb3-41af-8eed-74158641d0ec', 3: '3ec90013-f679-4f1c-859c-b1b9acd3c5b8', 4: 'de856b56-962b-40d2-a6b6-3ce9ed6eb9c4', 5: '48ab05d9-7b13-4955-8a11-c9e43278cf57', 6: '01926be0-d242-4bc3-b5b2-981ac80cac93', 7: '26abb1fb-db23-44de-bed9-2342ac35df5c', 8: '8223aee2-426a-4059-b37a-77abef43b1bf', 9: 'a45855cf-0201-4fc7-a6bd-30d4c003b5d9', 10: 'e64f3fb3-59fe-4101-94e3-aa92f7ccdaab', 11: '07da717a-3873-467c-8fa4-a1717000dc1c', 12: '6f3d2ca0-21f3-4459-86c7-839dbb2a6b07', 13: '42aa123c-8bf5-4329-add4-37bee2e737e1', 14: 'd508b7de-e08c-4000-8650-1d5fcffdf2e3', 15: '0b6060be-95f9-4e23-85f6-6bb7c208fb94', 16: '0468411a-3eb7-4f1a-b5e8-5643ca3a36e0', 17: '8545f207-2d36-4ad6-9708-1abf1853ac3c', 18: '5f664cde-af29-46b8-b072-48fb74903666', 19: 'e7ad4ad5-2701-4500-8689-8fd599fe61da', 20: 'e2bfc7af-b8f6-4605-926b-43f5f54c02aa', 21: 'd0f51b02-a847-4676-abb6-839b96c5f3a1', 22: 'fc782019-b37a-4575-9205-96874bd4b98e', 23: '95a558f9-05e6-46a1-9cb5-5e9f3d6ea5ce', 24: 'afde14d2-47e1-46ec-800c-3daf4a12b34a'})\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./save_fasiss/index.pkl\",\"rb\") as fs:\n",
    "    data = pickle.load(fs)\n",
    "    print(data)\n",
    "# 불러보면 임베딩된 값으로 저장하고 있음 \n",
    "# -> 이거 다시 돌리는거로 받으려면 load_local + embedding_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever\n",
    "리트리버(retriever)는 정보 검색 시스템에서 중요한 역할을 하는 컴포넌트로, 주어진 쿼리에 대해 관련 정보를 찾고 반환하는 기능을 담당 = 간단하게 **검색 도구**\n",
    "\n",
    "\"Vector stores can be used as the backbone of a retriever\"<br>\n",
    "\"Retrievers accept a string query as input and return a list of Document's as output.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever 생성\n",
    "retriever = db.as_retriever(search_type=\"mmr\", # Maximum Marginal Relevance\n",
    "                  search_kwargs={'k': 3, 'fetch_k': 8}) \n",
    "                # k :검색 시 선택할 최대 결과 수 (최종)\n",
    "                # fetch_k : 검색을 위해 가져올 결과 수 (후보)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140631844762432"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7fe76726b340>, search_type='mmr', search_kwargs={'k': 3, 'fetch_k': 8})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever\n",
    "# 다른 저장소 (ex Chroma)도 langchain의 하위 라이브러리에 저장되어있음\n",
    "# 따라서 tags에 어떤 라이브러리를 사용했는지 나와있고\n",
    "# vectorstore에는 FAISS 객체가 담겨있음\n",
    "# search_type과 search_kwargs에 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(id(db) == id(retriever.vectorstore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "<class 'langchain_core.documents.base.Document'>\n",
      "355\n",
      "303\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "outputs = retriever.invoke(\"코로나걸려서 기침이 나와\")\n",
    "print(len(outputs))\n",
    "print(type((outputs[0])))\n",
    "print(outputs[0].page_content.find(\"코로나\"))\n",
    "print(outputs[1].page_content.find(\"코로나\"))\n",
    "print(outputs[2].page_content.find(\"코로나\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remind\n",
    "\n",
    "지금까지 \n",
    "1. PDF 파일을 통해 먼저 문자열로 만들었고\n",
    "2. 그 문자열을 특정 단위로(청크) Spilt 했고\n",
    "3. 나눠진 데이터를 Embedding 모델을 통해 Vector로 만들면서\n",
    "4. FAISS를 통해 Vector DB에 저장했음\n",
    "5. 마지막으로 Vector DB를 통해 Retriever 객체를 만들어서 (질문-> 유사도높은 대답 후보)를 가능하게함\n",
    "\n",
    "\n",
    "중간 중간에 바꿀수 있는 것들\n",
    "- **PDF를 어떤 라이브러리를 통해서 문자열로 바꿀지**\n",
    "- **어떤 단위로 문서를 분리할지**\n",
    "- **어떤 임베딩 모델을 사용할지**\n",
    "- **어떤 Vector DB를 사용할지**\n",
    "- **어떤 방식으로 Vector를 찾을지 (파라미터)**\n",
    "\n",
    "### 추가 생각\n",
    "PDF의 테이블, 표, 그림으로 되어있는 자료는 불러올 때 인식하기 어려운 경우가 존재함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import fitz  # PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(file_path, chunk_size=800, chunk_overlap=50):\n",
    "    \"\"\"PDF 텍스트 추출 후 chunk 단위로 나누기\"\"\"\n",
    "    # PDF 파일 열기\n",
    "    doc = fitz.open(file_path)\n",
    "    text = ''\n",
    "    # 모든 페이지의 텍스트 추출\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    # 텍스트를 chunk로 분할\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )\n",
    "    chunk_temp = splitter.split_text(text)\n",
    "    # Document 객체 리스트 생성\n",
    "    chunks = [Document(page_content=t) for t in chunk_temp]\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def create_vector_db(chunks, model_path=\"intfloat/multilingual-e5-small\"):\n",
    "    \"\"\"FAISS DB 생성\"\"\"\n",
    "    # 임베딩 모델 설정\n",
    "    model_kwargs = {'device': 'cuda'}\n",
    "    encode_kwargs = {'normalize_embeddings': True}\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_path,\n",
    "        model_kwargs=model_kwargs,\n",
    "        encode_kwargs=encode_kwargs\n",
    "    )\n",
    "    # FAISS DB 생성 및 반환\n",
    "    db = FAISS.from_documents(chunks, embedding=embeddings)\n",
    "    return db\n",
    "\n",
    "def normalize_path(path):\n",
    "    \"\"\"경로 유니코드 정규화\"\"\"\n",
    "    return unicodedata.normalize('NFC', path)\n",
    "\n",
    "\n",
    "def process_pdfs_from_dataframe(df, base_directory):\n",
    "    \"\"\"딕셔너리에 pdf명을 키로해서 DB, retriever 저장\"\"\"\n",
    "    pdf_databases = {}\n",
    "    unique_paths = df['Source_path'].unique()\n",
    "    # unique_paths = unique_paths[:2]\n",
    "    \n",
    "    for path in tqdm(unique_paths, desc=\"Processing PDFs\"):\n",
    "        # 경로 정규화 및 절대 경로 생성\n",
    "        normalized_path = normalize_path(path)\n",
    "        full_path = os.path.normpath(os.path.join(base_directory, normalized_path.lstrip('./'))) if not os.path.isabs(normalized_path) else normalized_path\n",
    "        \n",
    "        pdf_title = os.path.splitext(os.path.basename(full_path))[0]\n",
    "        print(f\"Processing {pdf_title}...\")\n",
    "        \n",
    "        # PDF 처리 및 벡터 DB 생성\n",
    "        chunks = process_pdf(full_path)\n",
    "        db = create_vector_db(chunks)\n",
    "        \n",
    "        # Retriever 생성\n",
    "        retriever = db.as_retriever(search_type=\"mmr\", \n",
    "                                    search_kwargs={'k': 3, 'fetch_k': 8})\n",
    "        \n",
    "        # 결과 저장\n",
    "        pdf_databases[pdf_title] = {\n",
    "                'db': db,\n",
    "                'retriever': retriever\n",
    "        }\n",
    "    return pdf_databases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:   0%|          | 0/9 [00:00<?, ?it/s]/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 중소벤처기업부_혁신창업사업화자금(융자)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  11%|█         | 1/9 [00:05<00:47,  5.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 보건복지부_부모급여(영아수당) 지원...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  22%|██▏       | 2/9 [00:09<00:32,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 보건복지부_노인장기요양보험 사업운영...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  33%|███▎      | 3/9 [00:13<00:25,  4.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 산업통상자원부_에너지바우처...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  44%|████▍     | 4/9 [00:16<00:19,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 국토교통부_행복주택출자...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  56%|█████▌    | 5/9 [00:20<00:14,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 「FIS 이슈 & 포커스」 22-4호 《중앙-지방 간 재정조정제도》...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  67%|██████▋   | 6/9 [00:23<00:10,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 「FIS 이슈 & 포커스」 23-2호 《핵심재정사업 성과관리》...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  78%|███████▊  | 7/9 [00:26<00:06,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 「FIS 이슈&포커스」 22-2호 《재정성과관리제도》...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs:  89%|████████▉ | 8/9 [00:29<00:03,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 「FIS 이슈 & 포커스」(신규) 통권 제1호 《우발부채》...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing PDFs: 100%|██████████| 9/9 [00:33<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "base_directory = './data' # Your Base Directory\n",
    "df = pd.read_csv('./data/test.csv')\n",
    "pdf_databases = process_pdfs_from_dataframe(df, base_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습\n",
    "\n",
    "개발 환경이 좋지 않아서 작은 모델로 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Langchain 관련\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 호출\n",
    "\n",
    "개발환경의 문제로 양자화 & 16bit(모델 특성상 bf16)로 모델 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# 모델 ID \n",
    "model_id = \"EleutherAI/polyglot-ko-1.3b\"\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_use_double_quant=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_compute_dtype=torch.bfloat16\n",
    "#     )\n",
    "\n",
    "# 토크나이저 로드 및 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# 모델 로드 및 양자화 설정 적용\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "train을 위한 dataset은 아래와 같은 형태로 필수 column이 존재함\n",
    "\n",
    "따라서 적절한 tokenizer 함수를 통해 변환해 줘야함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files='/home/csh/workspace/LLM_study/data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SAMPLE_ID', 'Source', 'Source_path', 'Question', 'Answer'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/home/csh/workspace/LLM_study/data/train.csv').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['SAMPLE_ID', 'Source', 'Source_path', 'Question', 'Answer'],\n",
       "        num_rows: 496\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['SAMPLE_ID', 'Source', 'Source_path', 'Question', 'Answer'],\n",
       "        num_rows: 446\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['SAMPLE_ID', 'Source', 'Source_path', 'Question', 'Answer'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset['train'].train_test_split(test_size=0.1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "\n",
    "- **input_ids**\n",
    "\n",
    "모델에 입력되는 문장의 각 토큰을 나타내는 정수 인덱스 -> 모델의 vocabulary와 매핑되어있음 \n",
    "\n",
    "**token_type_ids**\n",
    "\n",
    "문장 쌍을 처리할 때 각 문장을 구분하는 데 사용. 일반적으로 두 문장이 입력으로 주어지는 경우(예: 질문-응답 쌍, 문장 쌍 분류 등), 이 배열은 각 토큰이 어떤 문장에 속하는지를 나타냅니다.\n",
    "\n",
    "**attention_mask**\n",
    "\n",
    "패딩(padding) 토큰과 실제 입력 토큰을 구분하는 데 사용<br> : 1은 실제 입력 토큰 / 0은 패딩 토큰\n",
    "모델은 패딩 토큰을 무시하고 실제 입력 토큰만을 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/446 [00:00<?, ? examples/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Map: 100%|██████████| 446/446 [00:00<00:00, 1811.01 examples/s]\n",
      "Map: 100%|██████████| 50/50 [00:00<00:00, 2033.56 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def tokenize_dataset(dataset):\n",
    "    re_dataset = tokenizer(dataset['Question'], padding=True, truncation=True)\n",
    "    label = tokenizer(dataset['Answer'], padding=True, truncation=True)\n",
    "    re_dataset['labels'] = label['input_ids']\n",
    "    return re_dataset\n",
    "\n",
    "dataset = dataset.map(tokenize_dataset, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['SAMPLE_ID', 'Source', 'Source_path', 'Question', 'Answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 446\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['SAMPLE_ID', 'Source', 'Source_path', 'Question', 'Answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 50\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2로 패딩된거는 여기선 <|endoftext|>\n",
    "tokenizer.decode(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA\n",
    "\n",
    "low rank로 변환해주는 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTNeoXForCausalLM(\n",
       "  (gpt_neox): GPTNeoXModel(\n",
       "    (embed_in): Embedding(30080, 2048)\n",
       "    (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x GPTNeoXLayer(\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (attention): GPTNeoXSdpaAttention(\n",
       "          (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "          (query_key_value): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (mlp): GPTNeoXMLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (act): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (embed_out): Linear(in_features=2048, out_features=30080, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA 적용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 6,291,456 || all params: 1,338,101,760 || trainable%: 0.4702\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=32,\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "p_model = get_peft_model(model, lora_config)\n",
    "p_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # Masked Language Model이 아닌 Causal Language Model의 경우 False로 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',              # 결과를 저장할 디렉토리\n",
    "    evaluation_strategy=\"steps\",         # 평가 전략을 \"steps\"로 설정\n",
    "    eval_steps=30,                      # 평가 간격 (스텝 단위)\n",
    "    learning_rate=2e-5,                  # 학습률\n",
    "    per_device_train_batch_size=4,       # 훈련 배치 크기\n",
    "    per_device_eval_batch_size=4,        # 평가 배치 크기\n",
    "    num_train_epochs=3,                  # 에폭 수\n",
    "    weight_decay=0.01,                   # 가중치 감소\n",
    "    logging_dir='./logs',                # 로그 디렉토리\n",
    "    logging_steps=10,                    # 로그 기록 간격\n",
    "    prediction_loss_only=True            # 생성 모델에서는 일반적으로 loss만을 예측\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Generate의 경우 SFT(Supervised-Fine-Tuning)Trainer 사용이 용이함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:289: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,                         # 모델\n",
    "    args=training_args,                  # 훈련 인수\n",
    "    train_dataset=dataset['train'],   # 훈련 데이터셋\n",
    "    eval_dataset=dataset['test'] ,  # 평가 데이터셋\n",
    "    tokenizer=tokenizer,                 # 토크나이저\n",
    "    data_collator=data_collator,           # 데이터 콜레이터\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 23:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.990600</td>\n",
       "      <td>2.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.751600</td>\n",
       "      <td>2.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.740600</td>\n",
       "      <td>2.680625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.218000</td>\n",
       "      <td>2.636875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.356300</td>\n",
       "      <td>2.601875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.180500</td>\n",
       "      <td>2.568125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.305500</td>\n",
       "      <td>2.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.098400</td>\n",
       "      <td>2.548750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.182800</td>\n",
       "      <td>2.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>2.371100</td>\n",
       "      <td>2.543750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>2.299200</td>\n",
       "      <td>2.543750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=336, training_loss=2.4826543898809526, metrics={'train_runtime': 1403.1646, 'train_samples_per_second': 0.954, 'train_steps_per_second': 0.239, 'total_flos': 499663657156608.0, 'train_loss': 2.4826543898809526, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# 모델 ID \n",
    "model_id = \"EleutherAI/polyglot-ko-1.3b\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    )\n",
    "\n",
    "# 토크나이저 로드 및 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# 모델 로드 및 양자화 설정 적용\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/csh/workspace/LLM_study/.venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFacePipeline`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# HuggingFacePipeline 객체 생성\n",
    "text_generation_pipeline = pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=128,\n",
    ")\n",
    "\n",
    "hf = HuggingFacePipeline(pipeline=text_generation_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(s):\n",
    "    \"\"\"유니코드 정규화\"\"\"\n",
    "    return unicodedata.normalize('NFC', s)\n",
    "\n",
    "def format_docs(docs):\n",
    "    \"\"\"검색된 문서들을 하나의 문자열로 포맷팅\"\"\"\n",
    "    context = \"\"\n",
    "    for doc in docs:\n",
    "        context += doc.page_content\n",
    "        context += '\\n'\n",
    "    return context\n",
    "\n",
    "# 결과를 저장할 리스트 초기화\n",
    "results = []\n",
    "\n",
    "# DataFrame의 각 행에 대해 처리\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Answering Questions\"):\n",
    "    # 소스 문자열 정규화\n",
    "    source = normalize_string(row['Source'])\n",
    "    question = row['Question']\n",
    "\n",
    "    # 정규화된 키로 데이터베이스 검색\n",
    "    normalized_keys = {normalize_string(k): v for k, v in pdf_databases.items()}\n",
    "    retriever = normalized_keys[source]['retriever']\n",
    "\n",
    "    # RAG 체인 구성\n",
    "    template = \"\"\"\n",
    "    다음 정보를 바탕으로 질문에 답하세요:\n",
    "    {context}\n",
    "\n",
    "    질문: {question}\n",
    "\n",
    "    답변:\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    # RAG 체인 정의\n",
    "    rag_chain = (\n",
    "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | hf\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 답변 추론\n",
    "    print(f\"Question: {question}\")\n",
    "    full_response = rag_chain.invoke(question)\n",
    "\n",
    "    print(f\"Answer: {full_response}\\n\")\n",
    "\n",
    "    # 결과 저장\n",
    "    results.append({\n",
    "        \"Source\": row['Source'],\n",
    "        \"Source_path\": row['Source_path'],\n",
    "        \"Question\": question,\n",
    "        \"Answer\": full_response\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용 샘플 파일 로드\n",
    "submit_df = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "\n",
    "# 생성된 답변을 제출 DataFrame에 추가\n",
    "submit_df['Answer'] = [item['Answer'] for item in results]\n",
    "submit_df['Answer'] = submit_df['Answer'].fillna(\"Nan\")     # 모델에서 빈 값 (NaN) 생성 시 채점에 오류가 날 수 있음 [ 주의 ]\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "submit_df.to_csv(\"./data/baseline_submission.csv\", encoding='UTF-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-study-YfWbGZHI-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
